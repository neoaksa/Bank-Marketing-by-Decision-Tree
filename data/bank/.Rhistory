child$obsCount <- nrow(data)
child$feature <- ''
}
else {
#choose the feature with the highest information gain
ig <- sapply(colnames(data)[-ncol(data)],
function(x) InformationGain(
table(data[,x], data[,ncol(data)])
)
)
feature <- names(ig)[ig == max(ig)][1]
node$feature <- feature
#take the subset of the data-set having that feature value
childObs <- split(data[,!(names(data) %in% feature)], data[,feature], drop = TRUE)
for(i in 1:length(childObs)) {
#construct a child having the name of that feature value
# child <- node$AddChild(paste(feature,":",names(childObs)[i]))
child <- node$AddChild(names(childObs)[i])
#if(class(childObs[[i]])=="factor"){childObs[[i]] <-as.data.frame(childObs[[i]])}
childObs[[i]] <-as.data.frame(childObs[[i]])
#call the algorithm recursively on the child and the subset
TrainID3(child, childObs[[i]], thredhold,purity)
}
}
}
# prediction
Predict <- function(tree, features) {
if (tree$children[[1]]$isLeaf) {
return (tree$children[[1]]$name)}
child <- tree$children[[as.character(features[tree$feature][[1]])]]
if(is.null(child)){
return ("no")}
return ( Predict(child, features))
}
# automatic bin
binconti <- function(df, conti.name, class.name){
subdf <- df[,c(conti.name,class.name)]
# sort by continus numbers ascedently
subdf <- subdf[order(subdf[,conti.name],subdf[,class.name]),]
# find the split point
temp <- subdf[1, class.name] # save previous point
enthropy.orgi <- Entropy(table(subdf[,class.name]))
rownum <- nrow(subdf)
# record gain and split point
gain <- NULL
splitpoint <- NULL
for(i in 2: rownum){
if(temp != subdf[i, class.name]){
# calculate inforgain
enthropy1 <- Entropy(table(subdf[1:i-1,class.name]))
enthropy2 <- Entropy(table(subdf[i:rownum,class.name]))
gain <- append(gain,enthropy.orgi - ((i-1)/rownum)*enthropy1 - ((rownum-i+1)/rownum)*enthropy2)
splitpoint <- append(splitpoint, subdf[i,conti.name])
temp <- subdf[i,class.name] # change to new class
}
}
point <- cbind(splitpoint, gain)
return (point)
}
# start to prepare date
#bank <- read.table("bank-full.csv", sep=";", header=T)
# bin for age
# banktemp <-bank
# bank <-banktemp
# bank$age <- cut(bank$age, breaks=c(-Inf, 20,30, 40,50,60,Inf),
#                 labels=c("~20","21~30","31~40","41~50","51~60","6~"))
# bank$age <- cut(bank$age, breaks=c(-Inf, 30,55,Inf),
#                 labels=c("~30","31~60","55~"))
#
# partition.table = table(bank$age,bank$y)
# row.sums = as.vector(rowSums(partition.table))
# prob = partition.table / row.sums
# mosaicplot(partition.table , shade = T, xlab = "age", ylab = "y", main = "Mosaic Plot")
# check for point to split continuous variables at
p<-binconti(bank, "age","y")
plot(p)
bank$age = cut(bank$age, breaks=c(-Inf, 61, Inf), labels=c("<61",">=61"))
summary(bank$age)
# bin for balance
p<-binconti(bank, "balance","y")
plot(p)
summary(bank$balance)
bank$balance <- cut(bank$balance, breaks=c(-Inf, 72,Inf),
labels=c("<72",">=72"))
summary(bank$balance)
partition.table = table(bank$balance,bank$y)
row.sums = as.vector(rowSums(partition.table))
prob = partition.table / row.sums
mosaicplot(partition.table , shade = T, xlab = "balance", ylab = "y", main = "Mosaic Plot")
# bin for pday
table(bank$pdays)  # too many nosie, skip
p<-binconti(bank, "pdays","y")
plot(p)
# start to build tree
# plot correlation matrix to determine related attributes
pairs(~y+month+contact+duration+pdays, data=bank)
pairs(~y+day+campaign+previous, data=bank)
# delete unrelated attribute
MyData = subset(bank,select = -c(month,contact,duration,pdays,day,campaign,previous))
# split to training and test data
MyData <- MyData[sample(1:nrow(MyData)),]
MyTest <- MyData[40001:45211,]
MyTrain <- MyData[1:40000,]
library(ROSE)
# oversampling training data
MyTrain <- ovun.sample(y ~ ., data = MyTrain, method = "both",N = 40000, p=0.5, seed=1)$data
MyTrain <- MyTrain[sample(1:nrow(MyData)),]
MyTrain <- MyTrain[MyTrain$y %in% c("yes","no"),]
# cross-validation
library(caret)
# set the sample thredhold and purity threhold
threshold.sample <- c(10,100,1000)
threshold.purity <- c(0.9)
# set error matrix for recording validation error
error.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
colnames(error.matrix) <- threshold.purity
rownames(error.matrix) <- threshold.sample
for(s in 1:length(threshold.sample)){
for(p in 1:length(threshold.purity)){
set.seed(1)
# set fold 10
fold = 10
idx <- createFolds(c(1:dim(MyTrain)[1]), k=fold)
error <- rep(0,fold)
# k fold
for (i in 1:fold){
# split training and validation datale
learn    <- MyTrain[-idx[[i]], ]
x.valid    <- MyTrain[idx[[i]], ]
y.valid    <- MyTrain[idx[[i]], ncol(MyTrain)]
# traning
bankNode = rootNode(MyData)
tree <- Node$new(bankNode)
TrainID3(tree, learn,threshold.sample[s],threshold.purity[p])
# validation
result <- rep(0,nrow(x.valid))
for(row in 1:nrow(x.valid)){
result[row]  <-  Predict(tree,x.valid[row,])
}
error[i] <- mean(result!=y.valid)
confusionMatrix(data = result, reference = y.valid, positive = "yes")
}
error.matrix[s,p] <- mean(error)
}
}
y <- c("y","y","n","y")
x <- c("y","y","y","n")
confusionMatrix(data = x, reference = y, positive = "y")
y <- c("y","y","n","y")
x <- c("y","y","y","n")
xx <- confusionMatrix(data = x, reference = y, positive = "y")
xx$table
xx$table[1,1]
xx$table[1,2]
y <- c("y","y","y","y")
x <- c("y","y","y","n")
xx <- confusionMatrix(data = x, reference = y, positive = "y")
xx$table[1,2]
y <- c("y","n","y","y")
x <- c("y","y","n","n")
xx <- confusionMatrix(data = x, reference = y, positive = "y")
xx$table[1,2]
xx$table
xx$overall
xx$overall$accuracy
xx$overall["accuracy"]
xx$overall[accuracy]
xx$overall
xx
y <- c("y","n","y","y")
x <- c("y","y","n","n")
xx <- confusionMatrix(data = x, reference = y, positive = "y", mode = "prec_recall")
xx
xx$overall
xx
View(xx)
View(xx)
xx$byClass
xx$byClass[F1]
xx$byClass["F1"]
xx$byClass[["F1"]]
# set error matrix for recording validation error
error.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
f1.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
colnames(error.matrix) <- threshold.purity
rownames(error.matrix) <- threshold.sample
for(s in 1:length(threshold.sample)){
for(p in 1:length(threshold.purity)){
set.seed(1)
# set fold 10
fold = 10
idx <- createFolds(c(1:dim(MyTrain)[1]), k=fold)
error <- rep(0,fold)
# k fold
for (i in 1:fold){
# split training and validation datale
learn    <- MyTrain[-idx[[i]], ]
x.valid    <- MyTrain[idx[[i]], ]
y.valid    <- MyTrain[idx[[i]], ncol(MyTrain)]
# traning
bankNode = rootNode(MyData)
tree <- Node$new(bankNode)
TrainID3(tree, learn,threshold.sample[s],threshold.purity[p])
# validation
result <- rep(0,nrow(x.valid))
for(row in 1:nrow(x.valid)){
result[row]  <-  Predict(tree,x.valid[row,])
}
error[i] <- mean(result!=y.valid)
cm <- confusionMatrix(data = result, reference = y.valid, positive = "yes",mode = "prec_recall")
f1 <- cm$byClass[["F1"]]
}
error.matrix[s,p] <- mean(error)
f1.matrix[s,p] <- f1
}
}
# set the sample thredhold and purity threhold
threshold.sample <- c(10,100,1000)
threshold.purity <- c(0.9)
# set error matrix for recording validation error
error.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
f1.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
colnames(error.matrix) <- threshold.purity
rownames(error.matrix) <- threshold.sample
for(s in 1:length(threshold.sample)){
for(p in 1:length(threshold.purity)){
set.seed(1)
# set fold 10
fold = 10
idx <- createFolds(c(1:dim(MyTrain)[1]), k=fold)
error <- rep(0,fold)
f1 <- rep(0,fold)
# k fold
for (i in 1:fold){
# split training and validation datale
learn    <- MyTrain[-idx[[i]], ]
x.valid    <- MyTrain[idx[[i]], ]
y.valid    <- MyTrain[idx[[i]], ncol(MyTrain)]
# traning
bankNode = rootNode(MyData)
tree <- Node$new(bankNode)
TrainID3(tree, learn,threshold.sample[s],threshold.purity[p])
# validation
result <- rep(0,nrow(x.valid))
for(row in 1:nrow(x.valid)){
result[row]  <-  Predict(tree,x.valid[row,])
}
error[i] <- mean(result!=y.valid)
cm <- confusionMatrix(data = result, reference = y.valid, positive = "yes",mode = "prec_recall")
f1[i] <- cm$byClass[["F1"]]
}
error.matrix[s,p] <- mean(error)
f1.matrix[s,p] <- mean(f1)
}
}
f1.matrix[
f1.matrix
# set the sample thredhold and purity threhold
threshold.sample <- c(10,100,1000,2000,5000)
threshold.purity <- c(0,6,0.8,0.9,0.05)
# set error matrix for recording validation error
error.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
f1.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
colnames(error.matrix) <- threshold.purity
rownames(error.matrix) <- threshold.sample
colnames(f1.matrix) <- threshold.purity
rownames(f1.matrix) <- threshold.sample
for(s in 1:length(threshold.sample)){
for(p in 1:length(threshold.purity)){
set.seed(1)
# set fold 10
fold = 10
idx <- createFolds(c(1:dim(MyTrain)[1]), k=fold)
error <- rep(0,fold)
f1 <- rep(0,fold)
# k fold
for (i in 1:fold){
# split training and validation datale
learn    <- MyTrain[-idx[[i]], ]
x.valid    <- MyTrain[idx[[i]], ]
y.valid    <- MyTrain[idx[[i]], ncol(MyTrain)]
# traning
bankNode = rootNode(MyData)
tree <- Node$new(bankNode)
TrainID3(tree, learn,threshold.sample[s],threshold.purity[p])
# validation
result <- rep(0,nrow(x.valid))
for(row in 1:nrow(x.valid)){
result[row]  <-  Predict(tree,x.valid[row,])
}
error[i] <- mean(result!=y.valid)
cm <- confusionMatrix(data = result, reference = y.valid, positive = "yes",mode = "prec_recall")
f1[i] <- cm$byClass[["F1"]]
}
error.matrix[s,p] <- mean(error)
f1.matrix[s,p] <- mean(f1)
}
}
# set the sample thredhold and purity threhold
threshold.sample <- c(10,100,1000,2000,5000)
threshold.purity <- c(0,7,0.8,0.9,0.95)
# set error matrix for recording validation error
error.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
f1.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
colnames(error.matrix) <- threshold.purity
rownames(error.matrix) <- threshold.sample
colnames(f1.matrix) <- threshold.purity
rownames(f1.matrix) <- threshold.sample
for(s in 1:length(threshold.sample)){
for(p in 1:length(threshold.purity)){
set.seed(1)
# set fold 10
fold = 10
idx <- createFolds(c(1:dim(MyTrain)[1]), k=fold)
error <- rep(0,fold)
f1 <- rep(0,fold)
# k fold
for (i in 1:fold){
# split training and validation datale
learn    <- MyTrain[-idx[[i]], ]
x.valid    <- MyTrain[idx[[i]], ]
y.valid    <- MyTrain[idx[[i]], ncol(MyTrain)]
# traning
bankNode = rootNode(MyData)
tree <- Node$new(bankNode)
TrainID3(tree, learn,threshold.sample[s],threshold.purity[p])
# validation
result <- rep(0,nrow(x.valid))
for(row in 1:nrow(x.valid)){
result[row]  <-  Predict(tree,x.valid[row,])
}
error[i] <- mean(result!=y.valid)
cm <- confusionMatrix(data = result, reference = y.valid, positive = "yes",mode = "prec_recall")
f1[i] <- cm$byClass[["F1"]]
}
error.matrix[s,p] <- mean(error)
f1.matrix[s,p] <- mean(f1)
}
}
plot(f1.matrix)
f1.matrix
# set the sample thredhold and purity threhold
threshold.sample <- c(10,100,500,1000,2000,5000)
threshold.purity <- c(0.7,0.8,0.9,0.95)
# set error matrix for recording validation error
error.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
f1.matrix <- matrix(rep(0,length(threshold.purity)*length(threshold.sample)),
nrow=length(threshold.sample),ncol=length(threshold.purity))
colnames(error.matrix) <- threshold.purity
rownames(error.matrix) <- threshold.sample
colnames(f1.matrix) <- threshold.purity
rownames(f1.matrix) <- threshold.sample
for(s in 1:length(threshold.sample)){
for(p in 1:length(threshold.purity)){
set.seed(1)
# set fold 10
fold = 10
idx <- createFolds(c(1:dim(MyTrain)[1]), k=fold)
error <- rep(0,fold)
f1 <- rep(0,fold)
# k fold
for (i in 1:fold){
# split training and validation datale
learn    <- MyTrain[-idx[[i]], ]
x.valid    <- MyTrain[idx[[i]], ]
y.valid    <- MyTrain[idx[[i]], ncol(MyTrain)]
# traning
bankNode = rootNode(MyData)
tree <- Node$new(bankNode)
TrainID3(tree, learn,threshold.sample[s],threshold.purity[p])
# validation
result <- rep(0,nrow(x.valid))
for(row in 1:nrow(x.valid)){
result[row]  <-  Predict(tree,x.valid[row,])
}
error[i] <- mean(result!=y.valid)
cm <- confusionMatrix(data = result, reference = y.valid, positive = "yes",mode = "prec_recall")
f1[i] <- cm$byClass[["F1"]]
}
error.matrix[s,p] <- mean(error)
f1.matrix[s,p] <- mean(f1)
}
}
plot(f1.matrix)
f1.matrix
pairs(f1.matrix)
max(f1.matrix)
View(f1.matrix)
View(f1.matrix)
View(f1.matrix)
View(f1.matrix)
install.packages("randomForest")
MyTrain
library(randomForest)
## Run the RANDOM FOREST EXAMPLE
x.learn <- MyData[1:30000,]
y.learn <- MyData[1:30000,ncol(MyData)]
x.test <- MyData[1:10000,]
y.test <- MyData[1:10000,ncol(MyData)]
bank.rf = randomForest(x.learn, y.learn, x.test,y.test)
round(importance(bank.rf),2)
## Plot all errors
bank.rf$predicted
plot(bank.rf)
bank.rf
x.learn
library(randomForest)
## Run the RANDOM FOREST EXAMPLE
x.learn <- MyData[1:30000,-ncol(MyData)]
y.learn <- MyData[1:30000,ncol(MyData)]
x.test <- MyData[1:10000,-ncol(MyData)]
y.test <- MyData[1:10000,ncol(MyData)]
bank.rf = randomForest(x.learn, y.learn, x.test,y.test)
round(importance(bank.rf),2)
## Plot all errors
plot(bank.rf)
bank.rf
x.learn
y.learn
x.test
y.test
plot(bank.rf)
bank.rf
predict(bank.rf, MyTest.x)
x.learn <- MyData[1:30000,-ncol(MyData)]
y.learn <- MyData[1:30000,ncol(MyData)]
x.test <- MyData[1:10000,-ncol(MyTest)]
y.test <- MyData[1:10000,ncol(MyTest)]
bank.rf = randomForest(x.learn, y.learn, x.test,y.test)
round(importance(bank.rf),2)
## Plot all errors
plot(bank.rf)
predict(bank.rf, MyTest.x)
predict(bank.rf, MyTest.x)
MyTest.x
MyTest.x <- MyTest[,-ncol(MyTest)]
MyTest.y <- MyTest[,ncol(MyTest)]
predict(bank.rf, MyTest.x)
MyTest.x
bank.rf
predict(bank.rf, MyTest.x)
bank.pred <- predict(bank.rf, MyTest.x)
bank.rf = randomForest(x.learn, y.learn, x.test,y.test, keep.forest = TRUE)
round(importance(bank.rf),2)
## Plot all errors
plot(bank.rf)
bank.pred <- predict(bank.rf, MyTest.x)
bank.pred
confusionMatrix(bank.pred,reference = MyTest.y, positive = "yes")
confusionMatrix(bank.pred,reference = MyTest.y, positive = "yes",mode = "prec_recall")
bankNode = rootNode(MyData)
tree <- Node$new(bankNode)
TrainID3(tree, learn,10,0.9)
MyTest.x <- MyTest[,-ncol(MyTest)]
MyTest.y <- MyTest[,ncol(MyTest)]
result.test <- rep(0,nrow(MyTest.x))
for(row in 1:nrow(MyTest.x)){
result.test[row]  <-  Predict(tree,MyTest.x[row,])
}
error.test <- mean(result.test!=MyTest.y)
confusionMatrix(data = tree, reference = MyTest.y, positive = "yes",mode = "prec_recall")
print(error.test)
confusionMatrix(data = tree, reference = MyTest.y, positive = "yes",mode = "prec_recall")
MyTest.x <- MyTest[,-ncol(MyTest)]
MyTest.y <- MyTest[,ncol(MyTest)]
result.test <- rep(0,nrow(MyTest.x))
result.pred  <-  Predict(tree,MyTest)
confusionMatrix(data = tree, reference = MyTest.y, positive = "yes",mode = "prec_recall")
MyTest.x <- MyTest[,-ncol(MyTest)]
MyTest.y <- MyTest[,ncol(MyTest)]
result.test <- rep(0,nrow(MyTest.x))
result.pred  <-  Predict(tree,MyTest)
Predict(tree,MyTest)
MyTest.x <- MyTest[,-ncol(MyTest)]
MyTest.y <- MyTest[,ncol(MyTest)]
result.test <- rep(0,nrow(MyTest.x))
result.pred  <-  Predict(tree,MyTest.x)
confusionMatrix(data = result.pred, reference = MyTest.y, positive = "yes",mode = "prec_recall")
print(error.test)
MyTest.x
Predict(tree,MyTest.x)
tree
bankNode = rootNode(MyData)
tree <- Node$new(bankNode)
TrainID3(tree,MyTrain,10,0.9) # threshold
MyTest.x <- MyTest[,-ncol(MyTest)]
MyTest.y <- MyTest[,ncol(MyTest)]
result.test <- rep(0,nrow(MyTest.x))
result.pred  <-  Predict(tree,MyTest.x)
confusionMatrix(data = result.pred, reference = MyTest.y, positive = "yes",mode = "prec_recall")
MyTest.x <- MyTest[,-ncol(MyTest)]
MyTest.y <- MyTest[,ncol(MyTest)]
result.test <- rep(0,nrow(MyTest.x))
result.pred  <-  Predict(tree,MyTest.x)
tree
MyTest.x <- MyTest[,-ncol(MyTest)]
MyTest.y <- MyTest[,ncol(MyTest)]
result.test <- rep(0,nrow(MyTest.x))
for(row in 1:nrow(MyTest.x)){
result[row]  <-  Predict(tree,MyTest.x[row,])
}
confusionMatrix(data = result, reference = MyTest.y, positive = "yes",mode = "prec_recall")
